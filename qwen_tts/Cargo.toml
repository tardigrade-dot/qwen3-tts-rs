[package]
name = "qwen_tts"
version = "0.1.1"
edition = "2024"
description = "Qwen3-TTS text-to-speech model implementation for Candle"
repository = "https://github.com/danielclough/qwen3-tts-rs"
keywords = ["tts", "speech-synthesis", "machine-learning", "qwen"]
categories = ["science"]
license = "MIT OR Apache-2.0"
readme = "../README.md"

[dependencies]
candle-core = { version = "0.9" }
candle-nn = { version = "0.9" }
candle-transformers = { version = "0.9" }
candle-flash-attn = { version = "0.9", optional = true }
# Pin float8 to exactly 0.5.0 - version 0.5.1 uses cudarc 0.19.x which conflicts with candle-core's 0.18.x
float8 = "=0.5.0"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
tracing = "0.1"
anyhow = "1"
rand_mt = "4"
rustfft = "6"
tokenizers = "0.21"
accelerate-src = { version = "0.3.2", optional = true }
bindgen_cuda = { version = "0.1.5", optional = true }
cudarc = { version = "0.19.0", optional = true }
half = { version = "2.5.0", optional = true }
intel-mkl-src = { version = "0.8.1", optional = true }

# Audio loading and processing
symphonia = { version = "0.5", features = ["all-codecs", "all-formats"], optional = true }
rubato = { version = "0.16", optional = true }
base64 = { version = "0.22", optional = true }
reqwest = { version = "0.12", features = ["blocking"], optional = true }

hound = "3.5"
hf-hub = "0.4"
safetensors = "0.7"
bytemuck = { version = "1", features = ["derive"] }
indicatif = { version = "0.18.4", optional = true }

[features]
default = []
progressbar = [
    "dep:indicatif"
]
accelerate = [
    "dep:accelerate-src",
    "candle-core/accelerate",
    "candle-nn/accelerate",
    "candle-transformers/accelerate",
]
cuda = [
    "candle-core/cuda",
    "candle-nn/cuda",
    "candle-transformers/cuda",
    "dep:bindgen_cuda",
]
cudnn = ["candle-core/cudnn", "candle-nn/cudnn", "candle-transformers/cudnn"]
flash-attn = ["cuda", "candle-transformers/flash-attn", "dep:candle-flash-attn"]
mkl = [
    "dep:intel-mkl-src",
    "candle-core/mkl",
    "candle-nn/mkl",
    "candle-transformers/mkl",
]
nccl = ["cuda", "cudarc/nccl", "dep:half"]
audio-loading = ["dep:symphonia", "dep:rubato", "dep:base64", "dep:reqwest"]
metal = ["candle-core/metal", "candle-nn/metal", "candle-transformers/metal"]
cudarc = ["dep:cudarc"]

# Testing feature - enables integration tests that download models from HuggingFace
# Usage: cargo test --features integration-tests
# Note: This will download ~600MB-2GB of model weights on first run
integration-tests = []

# Performance timing instrumentation
# Usage: cargo run --features timing
timing = []

# Run all platform-independent tests
# Usage: cargo test --features test-all
test-all = ["integration-tests"]

# Platform-specific test features (use these explicitly when on that platform)
test-all-macos = ["test-all", "metal", "audio-loading"]
test-all-cuda = ["test-all", "cuda", "audio-loading"]